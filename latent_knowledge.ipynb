{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c19b7bab",
   "metadata": {},
   "source": [
    "### Implement Contrast-Consistent Search (Adapted from [Collin Burns](https://github.com/jkmackie/language_exploration/tree/main/Burns-CCS))\n",
    "* Unsupervised learning to accurately answer yes-no input question\n",
    "* Recovers knowledge from model representations\n",
    "* Seeks mapping so yes-no probability is consistent and confident\n",
    "* For yes-no question, estimate probabililty of yes answer.  \n",
    "* If truth is \"consistent\", the no_probability = (1- yes_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "422725a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import datasets\n",
    "import platform\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForMaskedLM, AutoModelForCausalLM\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887f25b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows\n"
     ]
    }
   ],
   "source": [
    "print(platform.system())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c1a0667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (C:\\Users\\Owner\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dca98274ec8410e9c1d7dda274d6601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's just try IMDB for simplicity\n",
    "data = load_dataset(\"imdb\")[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "822d1853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217.316171"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size_in_bytes/10**6  #size in MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da93521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1037386",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v2-xxlarge were not used when initializing DebertaV2ForMaskedLM: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'deberta.embeddings.position_embeddings.weight', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForMaskedLM were not initialized from the model checkpoint at microsoft/deberta-v2-xxlarge and are newly initialized: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###  Selected model device: cuda:0   ###\n"
     ]
    }
   ],
   "source": [
    "model_name = \"deberta\"\n",
    "\n",
    "#Cache model weights - windows and mac. Use r\"string with special char like \\\" to ignore special char.\n",
    "cache_dir = \"./cache_model_weights\"\n",
    "\n",
    "if model_name == \"deberta\":\n",
    "    model_type = \"encoder\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v2-xxlarge\", cache_dir=cache_dir)\n",
    "    model = AutoModelForMaskedLM.from_pretrained(\"microsoft/deberta-v2-xxlarge\", cache_dir=cache_dir)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "print(\"###  Selected model device:\", model.device, \"  ###\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae803a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1897fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probably the biggestg the MST3K version.\n",
      "Previous reviewer Cl, so, overall, 8.75.\n",
      "CONTAINS \"SPOILER\" I, anger, and spirit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print text and label features.\n",
    "start = 12499\n",
    "end = 12502\n",
    "[print(s[0:20] + s[-20:]) for s in data['text'][start:end]]\n",
    "[label for label in data['label'][start:end]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f756f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probably the biggest thing about Wild Rebels that hurts it the most is the hero. He's got LOSER written all over him, but that doesn't stop him from \"getting the girl.\" Probably one of the world's worst race drivers imaginable, he decides to stop racing after he crashes his car. Well, his new job is ### REVIEW_MIDDLE_TRUNCATED ###  end, at the lighthouse scene, you'll wish that Rod gets killed with all the bikers. Get this: He's shot twice, once in the arm and once in the leg, and still manages to crawl up the stairs a little. If only Jeeter had better aim...<br /><br />Avoid this one unless you're watching the MST3K version. \n",
      "0\n",
      "\n",
      "Previous reviewer Claudio Carvalho gave a much better recap of the film's plot details than I could. What I recall mostly is that it was just so beautiful, in every sense - emotionally, visually, editorially - just gorgeous.<br /><br />If you like movies that are wonderful to look at, and also have  ### REVIEW_MIDDLE_TRUNCATED ###  />On a scale of 1 to 10, I'd give it about an 8.75. The only reason I shy away from 9 is that it is a mood piece. If you are in the mood for a really artistic, very romantic film, then it's a 10. I definitely think it's a must-see, but none of us can be in that mood all the time, so, overall, 8.75. \n",
      "1\n",
      "\n",
      "CONTAINS \"SPOILER\" INFORMATION. Watch this director's other film, \"Earth\", at some point. It's a better film, but this one isn't bad just different.<br /><br />A rare feminist point of view from an Indian filmmaker. Tradition, rituals, duty, secrets, and the portrayal of strict sex roles make this a ### REVIEW_MIDDLE_TRUNCATED ### f this film challenges her culture's traditions, but she shows us individual human beings who are trapped by their culture and gender. We come to really care about the characters and we don't see them as stereotypes. Each on surprises us with their humanity, vulgarity, tenderness, anger, and spirit. \n",
      "1\n",
      "\n",
      "This is my first Deepa Mehta film. I saw the film on TV in its Hindi version with its \"Sita\" character presented as Nita. I also note that it is Radha who underwent the allegorical trial by fire in the film and not Nita/Sita. Yet what I loved about the film was its screenplay by Ms Mehta, not her di ### REVIEW_MIDDLE_TRUNCATED ### t in this film. Ms Das sparkled due to her screen presence rather than her acting capability. All in all, the film's strength remains in the structure of the screenplay which is above average in terms of international cinema. I am sure Ms Mehta can hone her writing talents in her future screenplays. \n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print text and label features.\n",
    "start = 12499; end = 12503;\n",
    "\n",
    "for mystr, label in zip(data['text'][start:end], data['label'][start:end]):\n",
    "    print(mystr[0:300] + \" ### REVIEW_MIDDLE_TRUNCATED ### \" + mystr[-300:], f\"\\n{label}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509816c",
   "metadata": {},
   "source": [
    "### Helper functions - Extract hidden states given a model and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3810ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder_hidden_states(model, tokenizer, input_text, layer=-1):\n",
    "    \"\"\"\n",
    "    Given an encoder model and some text, gets the encoder hidden states (in a given layer, by default the last) \n",
    "    on that input text (where the full text is given to the encoder).\n",
    "\n",
    "    Returns a numpy array of shape (hidden_dim,)\n",
    "    \"\"\"\n",
    "    # tokenize\n",
    "    encoder_text_ids = tokenizer(input_text, truncation=True, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "    # forward pass with autograd deactivated\n",
    "    with torch.no_grad():\n",
    "        output = model(encoder_text_ids, output_hidden_states=True)\n",
    "\n",
    "    # get the appropriate hidden states\n",
    "    hs_tuple = output[\"hidden_states\"]\n",
    "    \n",
    "    hs = hs_tuple[layer][0, -1].detach().cpu().numpy()\n",
    "\n",
    "    return hs\n",
    "\n",
    "def get_encoder_decoder_hidden_states(model, tokenizer, input_text, layer=-1):\n",
    "    \"\"\"\n",
    "    Given an encoder-decoder model and some text, gets the encoder hidden states (in a given layer, by default the last) \n",
    "    on that input text (where the full text is given to the encoder).\n",
    "\n",
    "    Returns a numpy array of shape (hidden_dim,)\n",
    "    \"\"\"\n",
    "    # tokenize\n",
    "    encoder_text_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "    decoder_text_ids = tokenizer(\"\", return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        output = model(encoder_text_ids, decoder_input_ids=decoder_text_ids, output_hidden_states=True)\n",
    "\n",
    "    # get the appropriate hidden states\n",
    "    hs_tuple = output[\"encoder_hidden_states\"]\n",
    "    hs = hs_tuple[layer][0, -1].detach().cpu().numpy()\n",
    "\n",
    "    return hs\n",
    "\n",
    "def get_decoder_hidden_states(model, tokenizer, input_text, layer=-1):\n",
    "    \"\"\"\n",
    "    Given a decoder model and some text, gets the hidden states (in a given layer, by default the last) on that input text\n",
    "\n",
    "    Returns a numpy array of shape (hidden_dim,)\n",
    "    \"\"\"\n",
    "    # tokenize (adding the EOS token this time)\n",
    "    input_ids = tokenizer(input_text + tokenizer.eos_token, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, output_hidden_states=True)\n",
    "\n",
    "    # get the last layer, last token hidden states\n",
    "    hs_tuple = output[\"hidden_states\"]\n",
    "    hs = hs_tuple[layer][0, -1].detach().cpu().numpy()\n",
    "\n",
    "    return hs\n",
    "\n",
    "def get_hidden_states(model, tokenizer, input_text, layer=-1, model_type=\"encoder\"):\n",
    "    fn = {\"encoder\": get_encoder_hidden_states, \"encoder_decoder\": get_encoder_decoder_hidden_states,\n",
    "          \"decoder\": get_decoder_hidden_states}[model_type]\n",
    "\n",
    "    return fn(model, tokenizer, input_text, layer=layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ac4dc6",
   "metadata": {},
   "source": [
    "### Format data.  Get all the hidden states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1855f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_imdb(text, label):\n",
    "    \"\"\"\n",
    "    Given an imdb example (\"text\") and corresponding label (0 for negative, or 1 for positive), \n",
    "    returns a zero-shot prompt for that example (which includes that label as the answer).\n",
    "    \n",
    "    (This is just one example of a simple, manually created prompt.)\n",
    "    \"\"\"\n",
    "    return \"The following movie review expresses a \" + [\"negative\", \"positive\"][label] + \" sentiment:\\n\" + text\n",
    "\n",
    "\n",
    "def get_hidden_states_many_examples(model, tokenizer, data, model_type, n=100):\n",
    "    \"\"\"\n",
    "    Given an encoder-decoder model, a list of data, computes the contrast hidden states on n random examples.\n",
    "    Returns numpy arrays of shape (n, hidden_dim) for each candidate label, along with a boolean numpy array of shape (n,)\n",
    "    with the ground truth labels\n",
    "    \n",
    "    This is deliberately simple so that it's easy to understand, rather than being optimized for efficiency\n",
    "    \"\"\"\n",
    "    # setup\n",
    "    model.eval()\n",
    "    all_neg_hs, all_pos_hs, all_gt_labels = [], [], []\n",
    "\n",
    "    # loop\n",
    "    for _ in tqdm(range(n)):\n",
    "        # for simplicity, sample a random example until we find one that's a good length i.e. 400+ characters\n",
    "        while True:\n",
    "            idx = np.random.randint(len(data))\n",
    "            text, true_label = data[idx][\"text\"], data[idx][\"label\"]\n",
    "            # the actual formatted input will be longer, so include a bit of a margin\n",
    "            if len(tokenizer(text)) < 400:  \n",
    "                break\n",
    "                \n",
    "        # get hidden states\n",
    "        neg_hs = get_hidden_states(model, tokenizer, format_imdb(text, 0), model_type=model_type)\n",
    "        pos_hs = get_hidden_states(model, tokenizer, format_imdb(text, 1), model_type=model_type)\n",
    "\n",
    "        # collect\n",
    "        all_neg_hs.append(neg_hs)\n",
    "        all_pos_hs.append(pos_hs)\n",
    "        all_gt_labels.append(true_label)\n",
    "\n",
    "    all_neg_hs = np.stack(all_neg_hs)\n",
    "    all_pos_hs = np.stack(all_pos_hs)\n",
    "    all_gt_labels = np.stack(all_gt_labels)\n",
    "\n",
    "    return all_neg_hs, all_pos_hs, all_gt_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec2cb953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:04<01:26,  1.11it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 100/100 [00:53<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "neg_hs, pos_hs, y = get_hidden_states_many_examples(model, tokenizer, data, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e65ce99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1536)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (n_random_examples, hidden_dim)\n",
    "neg_hs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61dc1cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1536)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_hs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e1c18a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d309ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize = (15,8))\n",
    "ax1.hist(neg_hs.flatten(), bins=100, alpha=1, label='neg_hs', color='red')\n",
    "ax2.hist(pos_hs.flatten(), bins=100, alpha=1, label='pos_hs', color='green')\n",
    "ax1.legend(loc='upper right')\n",
    "ax2.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65026b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "565c5356",
   "metadata": {},
   "source": [
    "### Check that regression accuracy is high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4fe0fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Create a 50/50 train split (the data is already randomized).  Floor division returns largest possible integer quotient.\n",
    "n = len(y)\n",
    "neg_hs_train, neg_hs_test = neg_hs[:n//2], neg_hs[n//2:]\n",
    "pos_hs_train, pos_hs_test = pos_hs[:n//2], pos_hs[n//2:]\n",
    "y_train, y_test = y[:n//2], y[n//2:]\n",
    "\n",
    "# take the difference between positive and negative hidden states\n",
    "x_train = neg_hs_train - pos_hs_train\n",
    "x_test = neg_hs_test - pos_hs_test\n",
    "\n",
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "lr.fit(x_train, y_train)\n",
    "print(\"Logistic regression accuracy: {}\".format(lr.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a5ba41",
   "metadata": {},
   "source": [
    "## Contrast-Consistent Search (CCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1394f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPProbe(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d, 100)\n",
    "        self.linear2 = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.linear1(x))\n",
    "        o = self.linear2(h)\n",
    "        return torch.sigmoid(o)\n",
    "\n",
    "class CCS(object):\n",
    "    def __init__(self, x0, x1, nepochs=1000, ntries=10, lr=1e-3, batch_size=-1, \n",
    "                 verbose=False, device=\"cuda\", linear=True, weight_decay=0.01, var_normalize=False):\n",
    "        # data\n",
    "        self.var_normalize = var_normalize\n",
    "        self.x0 = self.normalize(x0)\n",
    "        self.x1 = self.normalize(x1)\n",
    "        self.d = self.x0.shape[-1]\n",
    "\n",
    "        # training\n",
    "        self.nepochs = nepochs\n",
    "        self.ntries = ntries\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        # probe\n",
    "        self.linear = linear\n",
    "        self.probe = self.initialize_probe()\n",
    "        self.best_probe = copy.deepcopy(self.probe)\n",
    "\n",
    "        \n",
    "    def initialize_probe(self):\n",
    "        if self.linear:\n",
    "            self.probe = nn.Linear(self.d, 1)\n",
    "        else:\n",
    "            self.probe = MLPProbe(self.d)\n",
    "        self.probe.to(self.device)    \n",
    "\n",
    "\n",
    "    def normalize(self, x):\n",
    "        \"\"\"\n",
    "        Mean-normalizes the data x (of shape (n, d))\n",
    "        If self.var_normalize, also divides by the standard deviation\n",
    "        \"\"\"\n",
    "        normalized_x = x - x.mean(axis=0, keepdims=True)\n",
    "        if self.var_normalize:\n",
    "            normalized_x /= normalized_x.std(axis=0, keepdims=True)\n",
    "\n",
    "        return normalized_x\n",
    "\n",
    "        \n",
    "    def get_tensor_data(self):\n",
    "        \"\"\"\n",
    "        Returns x0, x1 as appropriate tensors (rather than np arrays)\n",
    "        \"\"\"\n",
    "        x0 = torch.tensor(self.x0, dtype=torch.float, requires_grad=False, device=self.device)\n",
    "        x1 = torch.tensor(self.x1, dtype=torch.float, requires_grad=False, device=self.device)\n",
    "        return x0, x1\n",
    "    \n",
    "\n",
    "    def get_loss(self, p0, p1):\n",
    "        \"\"\"\n",
    "        Returns the CCS loss for two probabilities each of shape (n,1) or (n,)\n",
    "        \"\"\"\n",
    "        informative_loss = (torch.min(p0, p1)**2).mean(0) #a.k.a. confidence loss\n",
    "        consistent_loss = ((p0 - (1-p1))**2).mean(0)\n",
    "        return informative_loss + consistent_loss\n",
    "\n",
    "\n",
    "    def get_acc(self, x0_test, x1_test, y_test):\n",
    "        \"\"\"\n",
    "        Computes accuracy for the current parameters on the given test inputs\n",
    "        \"\"\"\n",
    "        x0 = torch.tensor(self.normalize(x0_test), dtype=torch.float, requires_grad=False, device=self.device)\n",
    "        x1 = torch.tensor(self.normalize(x1_test), dtype=torch.float, requires_grad=False, device=self.device)\n",
    "        with torch.no_grad():\n",
    "            p0, p1 = self.best_probe(x0), self.best_probe(x1)\n",
    "        avg_confidence = 0.5*(p0 + (1-p1))\n",
    "        predictions = (avg_confidence.detach().cpu().numpy() < 0.5).astype(int)[:, 0]\n",
    "        acc = (predictions == y_test).mean()\n",
    "        acc = max(acc, 1 - acc)\n",
    "\n",
    "        return acc\n",
    "    \n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Does a single training run of nepochs epochs\n",
    "        \"\"\"\n",
    "        x0, x1 = self.get_tensor_data()\n",
    "        permutation = torch.randperm(len(x0))\n",
    "        x0, x1 = x0[permutation], x1[permutation]\n",
    "        \n",
    "        # set up optimizer\n",
    "        optimizer = torch.optim.AdamW(self.probe.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        \n",
    "        batch_size = len(x0) if self.batch_size == -1 else self.batch_size\n",
    "        nbatches = len(x0) // batch_size\n",
    "\n",
    "        # Start training (full batch)\n",
    "        for epoch in range(self.nepochs):\n",
    "            for j in range(nbatches):\n",
    "                x0_batch = x0[j*batch_size:(j+1)*batch_size]\n",
    "                x1_batch = x1[j*batch_size:(j+1)*batch_size]\n",
    "            \n",
    "            # probe\n",
    "            p0, p1 = self.probe(x0_batch), self.probe(x1_batch)\n",
    "\n",
    "            # get the corresponding loss\n",
    "            loss = self.get_loss(p0, p1)\n",
    "\n",
    "            # update the parameters\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        return loss.detach().cpu().item()\n",
    "    \n",
    "    def repeated_train(self):\n",
    "        best_loss = np.inf\n",
    "        for train_num in range(self.ntries):\n",
    "            self.initialize_probe()\n",
    "            loss = self.train()\n",
    "            if loss < best_loss:\n",
    "                self.best_probe = copy.deepcopy(self.probe)\n",
    "                best_loss = loss\n",
    "\n",
    "        return best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f896bd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCS accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Train CCS without any labels\n",
    "ccs = CCS(neg_hs_train, pos_hs_train)\n",
    "ccs.repeated_train()\n",
    "\n",
    "# Evaluate\n",
    "ccs_acc = ccs.get_acc(neg_hs_test, pos_hs_test, y_test)\n",
    "print(\"CCS accuracy: {}\".format(ccs_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0971b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8336b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae890d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2666542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0758455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5437827c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed25da9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
